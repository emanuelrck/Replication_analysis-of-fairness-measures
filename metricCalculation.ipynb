{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZvJFJUMJc-3"
   },
   "source": [
    "# Import libraries and define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jFuqNRwljkDT"
   },
   "outputs": [],
   "source": [
    "!mkdir calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "frbcDgnJ80wQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N0C9QJbKjkDX"
   },
   "outputs": [],
   "source": [
    "dataCols = ['i_tp', 'i_fp', 'i_tn', 'i_fn', 'j_tp', 'j_fp', 'j_tn', 'j_fn']\n",
    "calculationsDir = \"calculations/\"\n",
    "datasetName = \"Set(08,56).bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SK8hWB3jkDY"
   },
   "source": [
    "# Get calculations\n",
    "As the dataset is quite large (4.2 Gb) we will write calculations to separate files in 2 stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WH776EQxjkDb"
   },
   "outputs": [],
   "source": [
    "def getGroupRatios(df):\n",
    "    return (df.j_tp + df.j_fp + df.j_tn + df.j_fn) / (df.i_tp + df.i_fp + df.i_tn + df.i_fn + df.j_tp + df.j_fp + df.j_tn + df.j_fn)\n",
    "\n",
    "def getImbalanceRatios(df):\n",
    "    return (df.i_tp + df.i_fn + df.j_tp + df.j_fn) / (df.i_tp + df.i_fp + df.i_tn + df.i_fn + df.j_tp + df.j_fp + df.j_tn + df.j_fn)\n",
    "\n",
    "def getTPR_i(df):\n",
    "    return df.i_tp / (df.i_tp + df.i_fn)\n",
    "\n",
    "def getTPR_j(df):\n",
    "    return df.j_tp / (df.j_tp + df.j_fn)\n",
    "\n",
    "def getFPR_i(df):\n",
    "    return df.i_fp / (df.i_fp + df.i_tn)\n",
    "\n",
    "def getFPR_j(df):\n",
    "    return df.j_fp / (df.j_fp + df.j_tn)\n",
    "\n",
    "def getPositivePredictiveValue_i(df):\n",
    "    return df.i_tp / (df.i_tp + df.i_fp)\n",
    "\n",
    "def getPositivePredictiveValue_j(df):\n",
    "    return df.j_tp / (df.j_tp + df.j_fp)\n",
    "\n",
    "def getNegativePredictiveValue_i(df):\n",
    "    return df.i_tn / (df.i_tn + df.i_fn)\n",
    "\n",
    "def getNegativePredictiveValue_j(df):\n",
    "    return df.j_tn / (df.j_tn + df.j_fn)\n",
    "\n",
    "#each group has the same probability of being classified with positive outcome\n",
    "def get_statistical_parity(df):\n",
    "    return ((df.j_tp + df.j_fp)/(df.j_tp + df.j_fp + df.j_tn + df.j_fn)) - ((df.i_tp + df.i_fp)/(df.i_tp + df.i_fp + df.i_tn + df.i_fn))\n",
    "\n",
    "#similiar to statistical parity, but using ratio\n",
    "def get_disparate_impact(df):\n",
    "    return ((df.j_tp + df.j_fp)/(df.j_tp + df.j_fp + df.j_tn + df.j_fn)) / ((df.i_tp + df.i_fp)/(df.i_tp + df.i_fp + df.i_tn + df.i_fn))\n",
    "\n",
    "#accuracy equality ratio\n",
    "def get_acc_equality_ratio(df):\n",
    "    return ((df.j_tp + df.j_tn)/(df.j_tp + df.j_fp + df.j_tn + df.j_fn)) / ((df.i_tp + df.i_tn)/(df.i_tp + df.i_fp + df.i_tn + df.i_fn))\n",
    "\n",
    "#accuracy equality difference\n",
    "def get_acc_equality_diff(df):\n",
    "    return ((df.j_tp + df.j_tn)/(df.j_tp + df.j_fp + df.j_tn + df.j_fn)) - ((df.i_tp + df.i_tn)/(df.i_tp + df.i_fp + df.i_tn + df.i_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3RXj2g1wILz"
   },
   "source": [
    "## Write calculations of the 1st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bnGu5_3kaTaR",
    "outputId": "5acd9406-b43d-4784-ede3-f50fc60d8208"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-3d8708a3-c011-4476-b435-e4b352f09133\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_tp</th>\n",
       "      <th>i_fp</th>\n",
       "      <th>i_tn</th>\n",
       "      <th>i_fn</th>\n",
       "      <th>j_tp</th>\n",
       "      <th>j_fp</th>\n",
       "      <th>j_tn</th>\n",
       "      <th>j_fn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d8708a3-c011-4476-b435-e4b352f09133')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-3d8708a3-c011-4476-b435-e4b352f09133 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-3d8708a3-c011-4476-b435-e4b352f09133');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   i_tp  i_fp  i_tn  i_fn  j_tp  j_fp  j_tn  j_fn\n",
       "0    56     0     0     0     0     0     0     0\n",
       "1    55     1     0     0     0     0     0     0\n",
       "2    55     0     1     0     0     0     0     0\n",
       "3    55     0     0     1     0     0     0     0\n",
       "4    55     0     0     0     1     0     0     0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get half of the data\n",
    "with open(datasetName, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns = dataCols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[:halfIdx]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCq6NgtX7fye",
    "outputId": "a507ee6c-32ec-4e61-d0c4-fa7f6c46e88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 276635335 entries, 0 to 276635334\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   i_tp    int8 \n",
      " 1   i_fp    int8 \n",
      " 2   i_tn    int8 \n",
      " 3   i_fn    int8 \n",
      " 4   j_tp    int8 \n",
      " 5   j_fp    int8 \n",
      " 6   j_tn    int8 \n",
      " 7   j_fn    int8 \n",
      "dtypes: int8(8)\n",
      "memory usage: 2.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2O6H_sXVlJFr",
    "outputId": "8c7b1a56-9887-415a-a14c-0fc566d555c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'collections': 378, 'collected': 3676, 'uncollectable': 0},\n",
       " {'collections': 36, 'collected': 314, 'uncollectable': 0},\n",
       " {'collections': 4, 'collected': 37, 'uncollectable': 0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate half of GRs\n",
    "with open(calculationsDir + \"gr.bin\", \"wb+\") as f:\n",
    "    getGroupRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "# Calculate half of IRs\n",
    "with open(calculationsDir + \"ir.bin\", \"wb+\") as f:\n",
    "    getImbalanceRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_tpr.bin\", \"wb+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"wb+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_fpr.bin\", \"wb+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"wb+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_ppv.bin\", \"wb+\") as f:\n",
    "    getPositivePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_ppv.bin\", \"wb+\") as f:\n",
    "    getPositivePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_npv.bin\", \"wb+\") as f:\n",
    "    getNegativePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"wb+\") as f:\n",
    "    getNegativePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"stat_parity.bin\", \"wb+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"disp_impact.bin\", \"wb+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_ratio.bin\", \"wb+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_diff.bin\", \"wb+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "# Free the memory\n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ1G6RB4wdby"
   },
   "source": [
    "## Append calculations of the 2st half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kYg-MGrluBpp"
   },
   "outputs": [],
   "source": [
    "with open(datasetName, \"rb\") as f:\n",
    "    df = pd.DataFrame(pickle.load(f), columns = dataCols)\n",
    "\n",
    "halfIdx = int(df.shape[0] / 2)\n",
    "df = df.iloc[halfIdx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZI6GFaih2eBR",
    "outputId": "3dfac9f1-d67b-42c4-f04a-10a7a860ffcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'collections': 376, 'collected': 3669, 'uncollectable': 0},\n",
       " {'collections': 36, 'collected': 300, 'uncollectable': 0},\n",
       " {'collections': 4, 'collected': 37, 'uncollectable': 0}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(calculationsDir + \"gr.bin\", \"ab+\") as f:\n",
    "    getGroupRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"ir.bin\", \"ab+\") as f:\n",
    "    getImbalanceRatios(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_tpr.bin\", \"ab+\") as f:\n",
    "    getTPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"ab+\") as f:\n",
    "    getTPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_fpr.bin\", \"ab+\") as f:\n",
    "    getFPR_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"ab+\") as f:\n",
    "    getFPR_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_ppv.bin\", \"ab+\") as f:\n",
    "    getPositivePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_ppv.bin\", \"ab+\") as f:\n",
    "    getPositivePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"i_npv.bin\", \"ab+\") as f:\n",
    "    getNegativePredictiveValue_i(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"ab+\") as f:\n",
    "    getNegativePredictiveValue_j(df).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"stat_parity.bin\", \"ab+\") as f:\n",
    "    get_statistical_parity(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"disp_impact.bin\", \"ab+\") as f:\n",
    "    get_disparate_impact(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_ratio.bin\", \"ab+\") as f:\n",
    "    get_acc_equality_ratio(df).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"acc_equality_diff.bin\", \"ab+\") as f:\n",
    "    get_acc_equality_diff(df).to_numpy().tofile(f)\n",
    "    \n",
    "del df\n",
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pq72mH7zjkDo",
    "outputId": "3c68f020-7283-4b07-b1cb-a5f51d515ad7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 58G\n",
      "drwxr-xr-x 2 root root 4.0K Nov 27 19:47 .\n",
      "drwxr-xr-x 1 root root 4.0K Nov 27 19:45 ..\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:50 acc_equality_diff.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:50 acc_equality_ratio.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:50 disp_impact.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:48 gr.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 i_fpr.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 i_npv.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 i_ppv.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:48 ir.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:48 i_tpr.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 j_fpr.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:50 j_npv.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 j_ppv.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:49 j_tpr.bin\n",
      "-rw-r--r-- 1 root root 4.2G Nov 27 19:50 stat_parity.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -lah calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeeOR3sTjkDo"
   },
   "source": [
    "The files are written as `float64`, while the dataset has data-type `int8`, thus the size of each file is the same as the size of the dataset because each of them contains one 8 times heavier column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOT3O2yajkDp"
   },
   "source": [
    "# Get additional calculations\n",
    "These calculations will be based on the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPbhIOmjjkDp"
   },
   "outputs": [],
   "source": [
    "#equal opportunity ratio of true positive rates\n",
    "def get_equal_opp_ratio(j_tpr, i_tpr):\n",
    "    return j_tpr / i_tpr\n",
    "\n",
    "#equal opportunity difference of true positive rates\n",
    "def get_equal_opp_diff(j_tpr, i_tpr):\n",
    "    return j_tpr - i_tpr\n",
    "\n",
    "#predictive equality ratio\n",
    "def get_pred_equality_ratio(j_fpr, i_fpr):\n",
    "    return j_fpr / i_fpr\n",
    "\n",
    "#predictive equality difference\n",
    "def get_pred_equality_diff(j_fpr, i_fpr):\n",
    "    return j_fpr - i_fpr\n",
    "\n",
    "#positive predictive parity ratio\n",
    "def get_pred_parity_ratio(j_ppv, i_ppv):\n",
    "    return j_ppv / i_ppv\n",
    "\n",
    "#positive predictive parity difference\n",
    "def get_pos_pred_parity_diff(j_ppv, i_ppv):\n",
    "    return j_ppv - i_ppv\n",
    "\n",
    "#negative predictive parity difference\n",
    "def get_neg_pred_parity_ratio(j_npv, i_npv):\n",
    "    return j_npv / i_npv\n",
    "\n",
    "#negative predictive parity difference\n",
    "def get_neg_pred_parity_diff(j_npv, i_npv):\n",
    "    return j_npv - i_npv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoYzFfdDjkDq"
   },
   "source": [
    "## Write 1st part\n",
    "Here the story is even worse as we need to open 2 files of the same size, so we will do it the same way: in 2 stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HURjnxCvoz20"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_tpr.bin\", \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns = [\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns = [\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[:halfIdx]\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_ratio.bin\", \"wb+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_diff.bin\", \"wb+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBH3rVXMjkDt"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_fpr.bin\", \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns = [\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns = [\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"pred_equality_ratio.bin\", \"wb+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"pred_equality_diff.bin\", \"wb+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "whFb_KUEjkDu"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_ppv.bin\", \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns = [\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[:halfIdx]\n",
    "    \n",
    "with open(calculationsDir + \"j_ppv.bin\", \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns = [\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"pred_parity_ratio.bin\", \"wb+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"pos_pred_parity_diff.bin\", \"wb+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DKvl3w7jkDv"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_npv.bin\", \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns = [\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns = [\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_ratio.bin\", \"wb+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_diff.bin\", \"wb+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRMFty8ajkDv"
   },
   "source": [
    "## Append 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bx8lLzTajkDw"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_tpr.bin\", \"rb\") as f:\n",
    "    i_tpr = pd.DataFrame(np.fromfile(f), columns = [\"i_tpr\"])\n",
    "    halfIdx = int(i_tpr.shape[0] / 2)\n",
    "    i_tpr = i_tpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"j_tpr.bin\", \"rb\") as f:\n",
    "    j_tpr = pd.DataFrame(np.fromfile(f), columns = [\"j_tpr\"])\n",
    "    halfIdx = int(j_tpr.shape[0] / 2)\n",
    "    j_tpr = j_tpr.iloc[halfIdx:]\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_ratio.bin\", \"ab+\") as f:\n",
    "    get_equal_opp_ratio(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"equal_opp_diff.bin\", \"ab+\") as f:\n",
    "    get_equal_opp_diff(j_tpr['j_tpr'], i_tpr['i_tpr']).to_numpy().tofile(f)\n",
    "\n",
    "del j_tpr\n",
    "del i_tpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_IGQKxACjkDx"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_fpr.bin\", \"rb\") as f:\n",
    "    i_fpr = pd.DataFrame(np.fromfile(f), columns = [\"i_fpr\"])\n",
    "    halfIdx = int(i_fpr.shape[0] / 2)\n",
    "    i_fpr = i_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"j_fpr.bin\", \"rb\") as f:\n",
    "    j_fpr = pd.DataFrame(np.fromfile(f), columns = [\"j_fpr\"])\n",
    "    halfIdx = int(j_fpr.shape[0] / 2)\n",
    "    j_fpr = j_fpr.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"pred_equality_ratio.bin\", \"ab+\") as f:\n",
    "    get_pred_equality_ratio(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "with open(calculationsDir + \"pred_equality_diff.bin\", \"ab+\") as f:\n",
    "    get_pred_equality_diff(j_fpr['j_fpr'], i_fpr['i_fpr']).to_numpy().tofile(f)\n",
    "    \n",
    "del j_fpr\n",
    "del i_fpr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SHgiWRQjkDy"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_ppv.bin\", \"rb\") as f:\n",
    "    i_ppv = pd.DataFrame(np.fromfile(f), columns = [\"i_ppv\"])\n",
    "    halfIdx = int(i_ppv.shape[0] / 2)\n",
    "    i_ppv = i_ppv.iloc[halfIdx:]\n",
    "    \n",
    "with open(calculationsDir + \"j_ppv.bin\", \"rb\") as f:\n",
    "    j_ppv = pd.DataFrame(np.fromfile(f), columns = [\"j_ppv\"])\n",
    "    halfIdx = int(j_ppv.shape[0] / 2)\n",
    "    j_ppv = j_ppv.iloc[halfIdx:]\n",
    "\n",
    "with open(calculationsDir + \"pred_parity_ratio.bin\", \"ab+\") as f:\n",
    "    get_pred_parity_ratio(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"pos_pred_parity_diff.bin\", \"ab+\") as f:\n",
    "    get_pos_pred_parity_diff(j_ppv['j_ppv'], i_ppv['i_ppv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_ppv\n",
    "del i_ppv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BKX-a8CjkDz"
   },
   "outputs": [],
   "source": [
    "with open(calculationsDir + \"i_npv.bin\", \"rb\") as f:\n",
    "    i_npv = pd.DataFrame(np.fromfile(f), columns = [\"i_npv\"])\n",
    "    halfIdx = int(i_npv.shape[0] / 2)\n",
    "    i_npv = i_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"j_npv.bin\", \"rb\") as f:\n",
    "    j_npv = pd.DataFrame(np.fromfile(f), columns = [\"j_npv\"])\n",
    "    halfIdx = int(j_npv.shape[0] / 2)\n",
    "    j_npv = j_npv.iloc[:halfIdx]\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_ratio.bin\", \"ab+\") as f:\n",
    "    get_neg_pred_parity_ratio(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "with open(calculationsDir + \"neg_pred_parity_diff.bin\", \"ab+\") as f:\n",
    "    get_neg_pred_parity_diff(j_npv['j_npv'], i_npv['i_npv']).to_numpy().tofile(f)\n",
    "\n",
    "del j_npv\n",
    "del i_npv\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations for sonya plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_metrics = [f.split('\\\\')[1] for f in glob.glob(calculationsDir+'*diff.bin')]\n",
    "diff_metrics = {'acc_equality_diff.bin': 'Accuracy equality difference', \n",
    "               'equal_opp_diff.bin': 'Equal opportunity difference', \n",
    "               'neg_pred_parity_diff.bin': 'Negative predictive parity difference', \n",
    "               'pos_pred_parity_diff.bin': 'Positive predictive parity difference', \n",
    "               'pred_equality_diff.bin': 'Predictive equality difference', \n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sonya(df, base_metric):   \n",
    "    diff_probs = {}\n",
    "    compute_diff_prob = lambda df: np.sum(df['diff'] == 0) / len(df)\n",
    "    \n",
    "    for metricFName in diff_metrics:\n",
    "        with open(metricFName, \"rb\") as f:\n",
    "            diff_metric = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"diff\"])\n",
    "        df = pd.concat([df, diff_metric], axis = 1)\n",
    "\n",
    "        diff = df.groupby(base_metric).apply(compute_diff_prob)\n",
    "        diff_probs[diff_metrics[metricFName]] = diff\n",
    "\n",
    "        df.drop('diff', axis=1, inplace=True)\n",
    "        \n",
    "    sonya = pd.DataFrame(diff_probs)\n",
    "    sonya *= 100\n",
    "    sonya.reset_index(inplace=True)\n",
    "    sonya.to_csv(calculationsDir + \"sonya_\" + base_metric + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ir.bin\", \"rb\") as f:\n",
    "    df = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"ir\"])\n",
    "calculate_sonya(df, 'ir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gr.bin\", \"rb\") as f:\n",
    "    df = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"gr\"])\n",
    "calculate_sonya(df, 'gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_parity = ((df.j_tp + df.j_fp)/(df.j_tp + df.j_fp + df.j_tn + df.j_fn)) - ((df.i_tp + df.i_fp)/(df.i_tp + df.i_fp + df.i_tn + df.i_fn))\n",
    "# stereotypical bias = abs(Mpos/totalM - Fpos/totalF)\n",
    "# abs(stat_parity) = stereotypical bias \n",
    "with open(\"stat_parity.bin\", \"rb\") as f:\n",
    "    df = pd.DataFrame(np.fromfile(f).astype(np.float16), columns = [\"st_bs\"])\n",
    "calculate_sonya(abs(df), 'st_bs')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:DS]",
   "language": "python",
   "name": "conda-env-DS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
